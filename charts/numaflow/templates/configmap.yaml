apiVersion: v1
data:
  namespaced: {{ .Values.configs.namespacedScope | quote }}
  managed.namespace: {{ .Values.configs.managedNamespace | quote }}
  controller.leader.election.disabled: {{ .Values.controller.configs.leaderElection.disabled | quote }}
  controller.leader.election.lease.duration: {{ .Values.controller.configs.leaderElection.leaseDuration | quote }}
  controller.leader.election.lease.renew.deadline: {{ .Values.controller.configs.leaderElection.renewDuration | quote }}
  controller.leader.election.lease.renew.period: {{ .Values.controller.configs.leaderElection.renewPeriod | quote }}
  server.insecure: {{ .Values.server.configs.insecure | quote }}
  server.port: "{{ include "server.configs.port" . }}"
  server.base.href: {{ .Values.server.configs.baseHref | quote }}
  server.readonly: {{ .Values.server.configs.readOnly | quote }}
  server.disable.auth: {{ .Values.server.configs.authDisable | quote }}
  server.dex.server: {{ .Values.server.configs.dexServer | quote }}
  server.address: "{{ .Values.server.configs.host }}:{{ include "server.configs.port" . }}"
  server.cors.allowed.origins: {{ .Values.server.configs.cors.allowedOrigin | quote }}
  server.daemon.client.protocol: {{ .Values.server.configs.daemon.client.protocol | quote }}
kind: ConfigMap
metadata:
  name: numaflow-cmd-params-config
  labels:
    {{- include "numaflow.labels" . | nindent 4 }}
  namespace: {{ .Release.Namespace }}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: numaflow-controller-config
  labels:
    {{- include "numaflow.labels" . | nindent 4 }}
  namespace: {{ .Release.Namespace }}
data:
  controller-config.yaml: |+
    # "instance" configuration can be used to run multiple Numaflow controllers, check details at https://numaflow.numaproj.io/operations/installation/#multiple-controllers
    instance: ""
    defaults:
      containerResources: |
        requests:
          memory: "128Mi"
          cpu: "100m"
    isbsvc:
      redis:
        # Default Redis settings, could be overridden by InterStepBufferService specs
        settings:
          # Redis config shared by both master and replicas
          redis: |
            min-replicas-to-write 1
            # Disable RDB persistence, AOF persistence already enabled.
            save ""
            # Enable AOF https://redis.io/topics/persistence#append-only-file
            appendonly yes
            auto-aof-rewrite-percentage 100
            auto-aof-rewrite-min-size 64mb
            maxmemory 512mb
            maxmemory-policy allkeys-lru
          # Special config only used by master
          master: ""
          # Special config only used by replicas
          replica: ""
          # Sentinel config
          sentinel: |
            sentinel down-after-milliseconds mymaster 10000
            sentinel failover-timeout mymaster 2000
            sentinel parallel-syncs mymaster 1
        versions:
          - version: 7.0.11
            redisImage: bitnami/redis:7.0.11-debian-11-r3
            sentinelImage: bitnami/redis-sentinel:7.0.11-debian-11-r3
            redisExporterImage: bitnami/redis-exporter:1.50.0-debian-11-r4
            initContainerImage: debian:latest
          - version: 7.0.15
            redisImage: bitnami/redis:7.0.15-debian-11-r2
            sentinelImage: bitnami/redis-sentinel:7.0.15-debian-11-r2
            redisExporterImage: bitnami/redis-exporter:1.56.0-debian-11-r2
            initContainerImage: debian:latest
      jetstream:
        # Default JetStream settings, could be overridden by InterStepBufferService specs
        settings: |
          # https://docs.nats.io/running-a-nats-service/configuration#limits
          # Only support to configure "max_payload".
          # Max payload size in bytes, defaults to 1 MB. It is not recommended to use values over 8MB but max_payload can be set up to 64MB.
          max_payload: 1048576
          # https://docs.nats.io/running-a-nats-service/configuration#jetstream
          # Only configure "max_memory_store" or "max_file_store", do not set "store_dir" as it has been hardcoded.
          # e.g. 1G. -1 means no limit, up to 75% of available memory. This only take effect for streams created using memory storage.
          max_memory_store: -1
          # e.g. 20G. -1 means no limit, Up to 1TB if available
          max_file_store: 1TB
        bufferConfig: |
          # The default properties of the buffers (streams) to be created in this JetStream service
          stream:
            # 0: Limits, 1: Interest, 2: WorkQueue
            retention: 0
            maxMsgs: 100000
            maxAge: 72h
            maxBytes: -1
            # 0: File, 1: Memory
            storage: 0
            replicas: 3
            duplicates: 60s
          # The default consumer properties for the created streams
          consumer:
            ackWait: 60s
            maxAckPending: 25000
          otBucket:
            maxValueSize: 0
            history: 1
            ttl: 3h
            maxBytes: 0
            # 0: File, 1: Memory
            storage: 0
            replicas: 3
          procBucket:
            maxValueSize: 0
            history: 1
            ttl: 72h
            maxBytes: 0
            # 0: File, 1: Memory
            storage: 0
            replicas: 3
        versions:
          - version: latest
            natsImage: nats:2.10.17
            metricsExporterImage: natsio/prometheus-nats-exporter:0.9.1
            configReloaderImage: natsio/nats-server-config-reloader:0.7.0
            startCommand: /nats-server
          - version: 2.8.1
            natsImage: nats:2.8.1
            metricsExporterImage: natsio/prometheus-nats-exporter:0.9.1
            configReloaderImage: natsio/nats-server-config-reloader:0.7.0
            startCommand: /nats-server
          - version: 2.8.1-alpine
            natsImage: nats:2.8.1-alpine
            metricsExporterImage: natsio/prometheus-nats-exporter:0.9.1
            configReloaderImage: natsio/nats-server-config-reloader:0.7.0
            startCommand: nats-server
          - version: 2.8.3
            natsImage: nats:2.8.3
            metricsExporterImage: natsio/prometheus-nats-exporter:0.9.1
            configReloaderImage: natsio/nats-server-config-reloader:0.7.0
            startCommand: /nats-server
          - version: 2.8.3-alpine
            natsImage: nats:2.8.3-alpine
            metricsExporterImage: natsio/prometheus-nats-exporter:0.9.1
            configReloaderImage: natsio/nats-server-config-reloader:0.7.0
            startCommand: nats-server
          - version: 2.9.0
            natsImage: nats:2.9.0
            metricsExporterImage: natsio/prometheus-nats-exporter:0.9.1
            configReloaderImage: natsio/nats-server-config-reloader:0.7.0
            startCommand: /nats-server
          - version: 2.9.0-alpine
            natsImage: nats:2.9.0-alpine
            metricsExporterImage: natsio/prometheus-nats-exporter:0.9.1
            configReloaderImage: natsio/nats-server-config-reloader:0.7.0
            startCommand: nats-server
          - version: 2.9.6
            natsImage: nats:2.9.6
            metricsExporterImage: natsio/prometheus-nats-exporter:0.9.1
            configReloaderImage: natsio/nats-server-config-reloader:0.7.0
            startCommand: /nats-server
          - version: 2.9.8
            natsImage: nats:2.9.8
            metricsExporterImage: natsio/prometheus-nats-exporter:0.9.1
            configReloaderImage: natsio/nats-server-config-reloader:0.7.0
            startCommand: /nats-server
          - version: 2.9.15
            natsImage: nats:2.9.15
            metricsExporterImage: natsio/prometheus-nats-exporter:0.9.1
            configReloaderImage: natsio/nats-server-config-reloader:0.7.0
            startCommand: /nats-server
          - version: 2.10.3
            natsImage: nats:2.10.3
            metricsExporterImage: natsio/prometheus-nats-exporter:0.9.1
            configReloaderImage: natsio/nats-server-config-reloader:0.7.0
            startCommand: /nats-server
          - version: 2.10.11
            natsImage: nats:2.10.11
            metricsExporterImage: natsio/prometheus-nats-exporter:0.9.1
            configReloaderImage: natsio/nats-server-config-reloader:0.7.0
            startCommand: /nats-server
          - version: 2.10.17
            natsImage: nats:2.10.17
            metricsExporterImage: natsio/prometheus-nats-exporter:0.9.1
            configReloaderImage: natsio/nats-server-config-reloader:0.7.0
            startCommand: /nats-server
---
apiVersion: v1
data:
  config.yaml: |-
    connectors:
      - type: github
        # https://dexidp.io/docs/connectors/github/
        id: github
        name: GitHub
        config:
          clientID: $GITHUB_CLIENT_ID
          clientSecret: $GITHUB_CLIENT_SECRET
          orgs:
            - name: <ORG_NAME>
              teams:
                - admin
                - readonly
kind: ConfigMap
metadata:
  name: numaflow-dex-server-config
  labels:
    {{- include "numaflow.labels" . | nindent 4 }}
  namespace: {{ .Release.Namespace }}
---
apiVersion: v1
data:
  admin.enabled: "true"
kind: ConfigMap
metadata:
  name: numaflow-server-local-user-config
  labels:
    {{- include "numaflow.labels" . | nindent 4 }}
  namespace: {{ .Release.Namespace }}
---
apiVersion: v1
data:
  rbac-conf.yaml: |
    policy.default: role:readonly
    # The scopes field controls which authentication scopes to examine during rbac enforcement.
    # We can have multiple scopes, and the first scope that matches with the policy will be used.
    # The default value is "groups", which means that the groups field of the user's token will be examined
    # The other possible value is "email", which means that the email field of the user's token will be examined
    # It can be provided as a comma-separated list, e.g "groups,email,username"
    policy.scopes: groups,email,username
  rbac-policy.csv: |
    # Policies go here
    p, role:admin, *, *, *
    p, role:readonly, *, *, GET
    # Groups go here
    # g, admin, role:admin
    # g, my-github-org:my-github-team, role:readonly
kind: ConfigMap
metadata:
  name: numaflow-server-rbac-config
  labels:
    {{- include "numaflow.labels" . | nindent 4 }}
  namespace: {{ .Release.Namespace }}
---
apiVersion: v1
data:
  config.yaml: |
    # url is a required field, it should be the url of the service to which the metrics proxy will connect
    # url: service_name + "." + service_namespace + ".svc.cluster.local" + ":" + port
    # example for local prometheus service
    # url: http://prometheus-operated.monitoring.svc.cluster.local:9090
    patterns:
      - name: vertex_gauge
        objects:
          - vertex
        title: Vertex Gauge Metrics
        description: This pattern represents the gauge metrics for a vertex across different dimensions
        expr: |
          sum($metric_name{$filters}) by ($dimension, period)
        params:
          - name: start_time
            required: false
          - name: end_time
            required: false
        metrics:
          - metric_name: vertex_pending_messages
            display_name: Vertex Pending Messages
            metric_description: This gauge metric keeps track of the total number of messages that are waiting to be processed over varying time frames of 1min, 5min, 15min and default period of 2min.
            # set "Units" or unset for default behaviour
            # unit: Units
            required_filters:
              - namespace
              - pipeline
              - vertex
            dimensions:
              - name: pod
                # expr: optional expression for prometheus query
                # overrides the default expression
                filters:
                  - name: pod
                    required: false
                  - name: period
                    required: false
              - name: vertex
                # expr: optional expression for prometheus query
                # overrides the default expression
                filters:
                  - name: period
                    required: false

      - name: mono_vertex_gauge
        objects:
          - mono-vertex
        title: MonoVertex Gauge Metrics
        description: This pattern represents the gauge metrics for a mono-vertex across different dimensions
        expr: |
          sum($metric_name{$filters}) by ($dimension, period)
        params:
          - name: start_time
            required: false
          - name: end_time
            required: false
        metrics:
          - metric_name: monovtx_pending
            display_name: MonoVertex Pending Messages
            metric_description: This gauge metric keeps track of the total number of messages that are waiting to be processed over varying time frames of 1min, 5min, 15min and default period of 2min.
            # set "Units" or unset for default behaviour
            # unit: Units
            required_filters:
              - namespace
              - mvtx_name
            dimensions:
              - name: pod
                # expr: optional expression for prometheus query
                # overrides the default expression
                filters:
                  - name: pod
                    required: false
                  - name: period
                    required: false
              - name: mono-vertex
                # expr: optional expression for prometheus query
                # overrides the default expression
                filters:
                  - name: period
                    required: false

      - name: mono_vertex_histogram
        objects:
          - mono-vertex
        title: MonoVertex Histogram Metrics
        description: This pattern is for P99, P95, P90 and P50 quantiles for a mono-vertex across different dimensions
        expr: |
          histogram_quantile($quantile, sum by($dimension,le) (rate($metric_name{$filters}[$duration])))
        params:
          - name: quantile
            required: true
          - name: duration
            required: true
          - name: start_time
            required: false
          - name: end_time
            required: false
        metrics:
          - metric_name: monovtx_processing_time_bucket
            display_name: MonoVertex Processing Time Latency
            metric_description: This metric represents a histogram to keep track of the total time taken to forward a chunk of messages.
            # set "Units" or unset for default behaviour otherwise set "s" or "ms" for latency metrics
            # Note: latency values are in μs
            # unit: s
            required_filters:
              - namespace
              - mvtx_name
            dimensions:
              - name: mono-vertex
              - name: pod
                filters:
                  - name: pod
                    required: false
          - metric_name: monovtx_sink_time_bucket
            display_name: MonoVertex Sink Write Time Latency
            metric_description: This metric represents a histogram to keep track of the total time taken to write to the Sink.
            # set "Units" or unset for default behaviour otherwise set "s" or "ms" for latency metrics
            # Note: latency values are in μs
            # unit: ms
            required_filters:
              - namespace
              - mvtx_name
            dimensions:
              - name: mono-vertex
              - name: pod
                filters:
                  - name: pod
                    required: false

      - name: vertex_throughput
        objects:
          - vertex
        title: Vertex Throughput and Message Rates
        description: This pattern measures the throughput of a vertex in messages per second across different dimensions
        expr: sum(rate($metric_name{$filters}[$duration])) by ($dimension)
        params:
          - name: duration
            required: true
          - name: start_time
            required: false
          - name: end_time
            required: false
        metrics:
          - metric_name: forwarder_data_read_total
            display_name: Vertex Read Processing Rate
            metric_description: This metric represents the total number of data messages read per second.
            # set "Units" or unset for default behaviour
            # unit: Units
            required_filters:
              - namespace
              - pipeline
              - vertex
            dimensions:
              - name: vertex
              - name: pod
                filters:
                  - name: pod
                    required: false

      - name: mono_vertex_throughput
        objects:
          - mono-vertex
        title: MonoVertex Throughput and Message Rates
        description: This pattern measures the throughput of a MonoVertex in messages per second across different dimensions.
        expr: sum(rate($metric_name{$filters}[$duration])) by ($dimension)
        params:
          - name: duration
            required: true
          - name: start_time
            required: false
          - name: end_time
            required: false
        metrics:
          - metric_name: monovtx_read_total
            display_name: MonoVertex Read Processing Rate
            metric_description: This metric represents the total number of data messages read per second.
            # set "Units" or unset for default behaviour
            # unit: Units
            required_filters:
              - namespace
              - mvtx_name
            dimensions:
              - name: mono-vertex
              - name: pod
                filters:
                  - name: pod
                    required: false

      - name: pod_cpu_memory_utilization
        objects:
          - mono-vertex
          - vertex
        title: CPU and Memory Utilisation by Pod
        description: This pattern represents the CPU and Memory utilisation by pod for mono-vertex and vertex
        expr: avg_over_time($metric_name{$filters}[$duration])
        params:
          - name: duration
            required: true
          - name: start_time
            required: false
          - name: end_time
            required: false
        metrics:
          # set your cpu metric name here
          - metric_name: namespace_pod_cpu_utilization
            display_name: Pod CPU Utilization
            metric_description: This metric represents the percentage utilization of cpu usage over cpu resource limits for a pod.
            required_filters:
              - namespace
              - pod
            dimensions:
              - name: mono-vertex
                filters:
                  - name: pod
                    # expr: optional expression for prometheus query
                    # overrides the default expression
                    required: false
              - name: vertex
                filters:
                  - name: pod
                    # expr: optional expression for prometheus query
                    # overrides the default expression
                    required: false
          # set your memory metric name here
          - metric_name: namespace_pod_memory_utilization
            display_name: Pod Memory Utilization
            metric_description: This metric represents the percentage utilization of memory usage in bytes over memory resource limits for a pod.
            required_filters:
              - namespace
              - pod
            dimensions:
              - name: mono-vertex
                filters:
                  - name: pod
                    # expr: optional expression for prometheus query
                    # overrides the default expression
                    required: false
              - name: vertex
                filters:
                  - name: pod
                    # expr: optional expression for prometheus query
                    # overrides the default expression
                    required: false

      - name: container_cpu_memory_utilization
        objects:
          - mono-vertex
          - vertex
        title: CPU and Memory Utilisation by Container
        description: This pattern represents the CPU and Memory utilisation by container for mono-vertex and vertex
        expr: avg_over_time($metric_name{$filters}[$duration])
        params:
          - name: duration
            required: true
          - name: start_time
            required: false
          - name: end_time
            required: false
        metrics:
          # set your cpu metric name here
          - metric_name: namespace_app_container_cpu_utilization
            display_name: Container CPU Utilization
            metric_description: This metric represents the percentage utilization of cpu usage over cpu resource limits for a container.
            required_filters:
              - namespace
            dimensions:
              - name: mono-vertex
                filters:
                  - name: container
                    # expr: optional expression for prometheus query
                    # overrides the default expression
                    required: false
              - name: vertex
                filters:
                  - name: container
                    # expr: optional expression for prometheus query
                    # overrides the default expression
                    required: false
          # set your memory metric name here
          - metric_name: namespace_app_container_memory_utilization
            display_name: Container Memory Utilization
            metric_description: This metric represents the percentage utilization of memory usage in bytes over memory resource limits for a container.
            required_filters:
              - namespace
            dimensions:
              - name: mono-vertex
                filters:
                  - name: container
                    # expr: optional expression for prometheus query
                    # overrides the default expression
                    required: false
              - name: vertex
                filters:
                  - name: container
                    # expr: optional expression for prometheus query
                    # overrides the default expression
                    required: false
kind: ConfigMap
metadata:
  name: numaflow-server-metrics-proxy-config
  labels:
    {{- include "numaflow.labels" . | nindent 4 }}
  namespace: {{ .Release.Namespace }}